---
title: ' Midterm'
author: "Srinivasa Phani Madhav"
date: "3/28/2024"
output: pdf_document
---

```{r}

library(caret)
library(neuralnet)
library(keras)
library(tidyverse)
library(tensorflow)
library(dplyr)
library(cloudml)
library(randomForest)
library(rpart)
library(rattle)

```
# Part 1

# 1

```{r}
data <- read.csv("C:/Users/MSP/Downloads/Unknown.csv",header = T)
head(data)
data = na.omit(data)
cat('There are', nrow(data), 'observations left.')
```

```{r}
set.seed(123)
training.samples <- data$y %>%
  createDataPartition(p = 0.75, list = FALSE)
train.data  <- data[training.samples, ]
test.data <- data[-training.samples, ]
str(train.data)
str(test.data)
```
# 2

```{r}
set.seed(123)
model1 = neuralnet(y~., data = train.data, hidden = 2, err.fct = "ce",act.fct = "logistic", linear.output = F)
plot(model1, rep = "best") # plot the model

probabilities = predict(model1, test.data)
predicted.classes = ifelse(probabilities > 0.5, 1, 0)

(c1 = confusionMatrix(factor(predicted.classes), factor(test.data$y), positive = "1"))
```

# 3

```{r}
detach(package:keras,unload=TRUE)
detach(package:tensorflow,unload=TRUE)

train.data$y = as.factor(train.data$y)
test.data$y = as.factor(test.data$y)

set.seed(123)
model2 = train(
  y ~., data = train.data, method = "rpart",
  trControl = trainControl("cv", number = 10),
  tuneLength = 10)
plot(model2)
model2$bestTune
fancyRpartPlot(model2$finalModel)

pred = predict(model2, newdata = test.data)
(c2 = confusionMatrix(pred, factor(test.data$y), positive = "1"))
```
#4

```{r}
predictions <- data.frame(
  Neural_Network_Prediction = predicted.classes,
  Pruned_Tree_Prediction = pred
)
# Create a 2x2 table to show agreement between predictions
agreement_table <- table(predictions$Neural_Network_Prediction, predictions$Pruned_Tree_Prediction)

# Output the agreement table
print("Agreement Table:")
print(agreement_table)
```

# Part2

# 1

```{r}
data1 = read.csv("C:/Users/MSP/Downloads/Madness.csv")
data1$x15 = ifelse(data1$x15 == 'y', 1, 0)
mean = mean(data1$y)
sd = sd(data1$y)
data1 = data.frame(scale(data1))
data = na.omit(data1)

cat('There are', nrow(data1) - nrow(data), 'missing values.')
```
```{r}
set.seed(123)
training.samples <- data$y %>%
  createDataPartition(p = 0.75, list = FALSE)
train.data  <- data[training.samples, ]
test.data <- data[-training.samples, ]
str(train.data)
str(test.data)
```
# 2
```{r}

library(keras)

train_x <- as.matrix(subset(train.data, select = -y))
train_y <- as.matrix(subset(train.data, select = y))
test_x <- as.matrix(subset(test.data, select = -y))
test_y <- as.matrix(subset(test.data, select = y))

set.seed(123)

model3 <- keras_model_sequential() 
model3 %>%
  layer_dense(units = 2, activation = 'linear', input_shape = c(ncol(train_x))) %>%
  layer_dense(units = 1, activation = "linear")

model3 %>% compile(loss='mse', optimizer='adam', metrics='mse')

summary(model3)

history <- model3 %>% fit(train_x, train_y, epochs = 50, batch_size = 8, validation_split = 0.1)
plot(history)

preds <- predict(model3, test_x)
scaled_RMSE <- sqrt(mean((test_y - preds)^2))

mean_y <- mean(test.data$y)
sd_y <- sd(test.data$y)
test_RMSE <- sqrt(mean(((test_y * sd_y + mean_y) - (preds * sd_y + mean_y))^2))

scaled_RMSE

test_RMSE
```

# 3

```{r}
detach(package:keras,unload=TRUE)


model4 = train(
  y ~., data = train.data, method = "rpart",
  trControl = trainControl("cv", number = 10),
  tuneLength = 100)
plot(model4)
model4$bestTune
fancyRpartPlot(model4$finalModel)
predictions = model4 %>% predict(test.data)

# scaled test RMSE
RMSE(test.data$y, predictions)
# test RMSE
RMSE(test.data$y*sd+mean, predictions*sd+mean)
```
